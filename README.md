# Cours Complet ArgoCD : De la Th√©orie √† la Production avec GitOps

![ArgoCD Logo](https://raw.githubusercontent.com/argoproj/argo-cd/master/docs/assets/argo.png)

üéØ Pr√©sentation du cours : ArgoCD en pratique

Bienvenue dans ce cours pratique sur ArgoCD !

En tant que professionnels du DevOps, nous savons que la r√©ussite de nos d√©ploiements repose sur trois piliers : automatisation, fiabilit√© et coh√©rence.
Ce programme a √©t√© pens√© comme un atelier concret et immersif, pour vous initier √† l‚Äôapproche GitOps et d√©couvrir comment ArgoCD transforme la livraison continue sur Kubernetes.

üöÄ Pourquoi suivre ce cours ?

- Comprendre et appliquer le paradigme GitOps au sein de vos projets.

- D√©ployer et g√©rer vos applications Kubernetes avec simplicit√© et efficacit√©.

- Mettre en place une cha√Æne CI/CD moderne gr√¢ce √† ArgoCD et GitHub Actions.

- Gagner en autonomie sur la gestion de vos environnements (dev, staging, production).

üéì Objectifs p√©dagogiques

- √Ä l‚Äôissue de ce cours, vous serez capable de :

- Installer et configurer ArgoCD dans un cluster Kubernetes.

- D√©clarer et synchroniser vos applications √† partir de d√©p√¥ts Git.

- Automatiser vos d√©ploiements en appliquant les bonnes pratiques GitOps.

- Construire un pipeline CI/CD complet avec GitHub Actions et ArgoCD.

üë• Public cible

- Administrateurs syst√®mes et ing√©nieurs DevOps.

- D√©veloppeurs souhaitant industrialiser leurs d√©ploiements Kubernetes.

- Toute personne d√©sirant ma√Ætriser l‚Äôapproche GitOps dans un contexte professionnel.

## Table des Mati√®res

1.  [**Introduction : Pourquoi ArgoCD dans une d√©marche DevOps ?**](#1--introduction--pourquoi-argocd-dans-une-d√©marche-devops-)
    *   Les limites du CI/CD traditionnel (Push)
    *   Le GitOps comme "Single Source of Truth" (Pull)
    *   Les b√©n√©fices d'ArgoCD
2.  [**Architecture et Fonctionnement**](#2--architecture-et-fonctionnement)
    *   Les 3 composants cl√©s d'ArgoCD
    *   Le cycle de r√©conciliation
3.  [**Atelier 1 : Installation de l'Environnement de Travail**](#3--atelier-1--installation-de-lenvironnement-de-travail)
    *   Pr√©requis
    *   Installation de K3s sur Amazon Linux
    *   Installation d'ArgoCD avec Helm
    *   Acc√®s √† l'interface ArgoCD
4.  [**Atelier 2 : D√©ploiement d'Applications avec ArgoCD**](#4--atelier-2--d√©ploiement-dapplications-avec-argocd)
    *   **Cas 1 : D√©ploiement d'Odoo 18 via l'UI (Chart Helm Existant)**
    *   **Cas 2 : Pr√©paration de notre application "Site Vitrine"**
        *   Cr√©ation du code source et des manifestes Kubernetes
        *   Cr√©ation du d√©p√¥t GitHub
    *   **Cas 3 : D√©ploiement du "Site Vitrine" via l'UI (D√©p√¥t Git Priv√©)**
5.  [**Atelier 3 : Workflow CI/CD Complet avec GitHub Actions**](#5--atelier-3--workflow-cicd-complet-avec-github-actions)
    *   Le concept : Git est la seule source de v√©rit√©
    *   Mise en place du pipeline GitHub Actions
    *   D√©monstration du workflow automatis√©
6.  [**Concepts Avanc√©s**](#6--concepts-avanc√©s)
    *   **ArgoCD et le Multi-Cluster**
        *   Enregistrer un second cluster
        *   D√©ployer sur un cluster distant
    *   **Notifications avec Slack**
        *   Configuration du webhook Slack
        *   Mise √† jour de notre application pour les notifications
7.  [**Conclusion**](#7--conclusion)
8.  [**Examen de Validation : D√©ployez votre Propre Application**](#8--examen-de-validation--d√©ployez-votre-propre-application)


---

## 1. Introduction : Pourquoi ArgoCD dans une d√©marche DevOps ?

Dans un pipeline CI/CD "classique", c'est souvent le serveur de CI (Jenkins, GitLab CI, GitHub Actions) qui, apr√®s avoir construit une image, la "pousse" vers Kubernetes √† l'aide de `kubectl apply` ou `helm upgrade`.

**Cette approche (Push) pr√©sente des d√©fis :**
*   **S√©curit√© :** Le syst√®me de CI a besoin de credentials puissants pour acc√©der au cluster Kubernetes. C'est une surface d'attaque importante.
*   **Coh√©rence :** Qu'est-ce qui est r√©ellement d√©ploy√© sur le cluster ? L'√©tat du cluster peut d√©river de ce qui est dans Git si des modifications manuelles (`kubectl edit`) sont faites.
*   **Audit :** Il est difficile de savoir qui a chang√© quoi et quand directement depuis l'√©tat du cluster.

**Le GitOps propose un mod√®le inverse (Pull) :**
Le d√©p√¥t **Git est la seule et unique source de v√©rit√©** (`Single Source of Truth`). L'√©tat d√©sir√© de notre infrastructure est d√©crit de mani√®re d√©clarative dans Git (fichiers YAML Kubernetes, charts Helm, etc.).

**ArgoCD** est un agent qui tourne dans notre cluster et dont le r√¥le est de s'assurer que l'√©tat *r√©el* du cluster correspond en permanence √† l'√©tat *d√©sir√©* dans Git.

**B√©n√©fices imm√©diats :**
*   **D√©ploiements fiables et reproductibles :** Tout est dans Git. Pour revenir en arri√®re, il suffit de faire un `git revert`.
*   **S√©curit√© renforc√©e :** Le cluster n'expose plus ses credentials. C'est ArgoCD, √† l'int√©rieur, qui tire les changements.
*   **D√©tection de la d√©rive (Drift Detection) :** Toute modification manuelle sur le cluster est imm√©diatement d√©tect√©e (et peut √™tre automatiquement annul√©e).
*   **Exp√©rience d√©veloppeur am√©lior√©e :** Les d√©veloppeurs n'ont plus besoin de conna√Ætre `kubectl`. Ils font ce qu'ils savent faire : une `pull request`.

## 2. Architecture et Fonctionnement

ArgoCD est simple mais puissant. Il repose sur 3 composants principaux :

1.  **API Server :** C'est la porte d'entr√©e. Elle expose une API gRPC/REST qui est utilis√©e par l'interface web (UI), la CLI (`argocd`), et les webhooks. Elle g√®re l'authentification, les autorisations et la coordination des autres services.

2.  **Repository Server :** Ce service est responsable de cloner vos d√©p√¥ts Git en local et de g√©n√©rer les manifestes Kubernetes. Il met en cache les d√©p√¥ts pour √©viter de surcharger Git. C'est lui qui transforme un Chart Helm ou un fichier Kustomize en YAML Kubernetes pur.

3.  **Application Controller :** C'est le c≈ìur d'ArgoCD. Ce contr√¥leur Kubernetes surveille en permanence les applications d√©ploy√©es. Pour chaque application, il compare l'√©tat d√©sir√© (les manifestes g√©n√©r√©s par le Repository Server depuis Git) avec l'√©tat actuel dans le cluster. Si une diff√©rence est d√©tect√©e, l'application est marqu√©e comme `OutOfSync`. Le contr√¥leur peut alors (selon la configuration) corriger l'√©tat du cluster pour qu'il corresponde √† Git.

Ce cycle de comparaison et de correction est appel√© le **cycle de r√©conciliation**.

## 3. Atelier 1 : Installation de l'Environnement de Travail

### Pr√©requis
*   Un compte AWS avec un serveur Amazon Linux 2 ou 2023.
*   Un client SSH pour vous connecter √† votre instance.
*   [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/) install√© sur votre machine locale.
*   [Helm](https://helm.sh/docs/intro/install/) install√© sur votre machine locale.

### Installation de K3s sur Amazon Linux

K3s est une distribution Kubernetes l√©g√®re et certifi√©e, parfaite pour nos ateliers. Connectez-vous en SSH √† votre instance EC2 et ex√©cutez :

```bash
# Installation de K3s
curl -sfL https://get.k3s.io | sh -

# K3s installe son propre containerd, mais il peut y avoir des conflits si Docker est d√©j√† l√†.
# Cette commande assure que le service k3s est bien d√©marr√©.
sudo systemctl start k3s

# Attendre quelques instants que le serveur soit pr√™t.
# V√©rifier que le cluster est fonctionnel (depuis le serveur)
sudo k3s kubectl get nodes
```

Pour piloter le cluster depuis votre machine locale, r√©cup√©rez le fichier de configuration :

```bash
# Sur le serveur EC2
sudo cat /etc/rancher/k3s/k3s.yaml
```

Copiez le contenu de ce fichier. Sur votre machine locale, collez-le dans `~/.kube/config`. **Attention :** Modifiez l'IP `127.0.0.1` par l'adresse IP publique de votre instance EC2.

```yaml
# Exemple de fichier ~/.kube/config modifi√©
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: <DONNEES_CERTIFICAT>
    server: https://<IP_PUBLIQUE_EC2>:6443 # <-- MODIFIEZ ICI
  name: default
...
```

Testez la connexion depuis votre machine locale :
```bash
kubectl get nodes
# Vous devriez voir le n≈ìud de votre serveur EC2.
```
### Installation helm
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install curl -y
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
helm version
helm repo add stable https://charts.helm.sh/stable
helm repo update
helm version
# Vous devriez voir la version de votre helm install√©.
```

<img width="1215" height="50" alt="image" src="https://github.com/user-attachments/assets/81ce7b42-b4f1-4a84-a2f9-7c296a18f3c9" />

### Installation d'ArgoCD avec Helm

Nous allons installer ArgoCD dans son propre namespace.

```bash
# 1. Cr√©er le namespace pour ArgoCD
kubectl create namespace argocd

# 2. Ajouter le d√©p√¥t Helm d'ArgoCD
helm repo add argo https://argoproj.github.io/argo-helm

# 3. Mettre √† jour les d√©p√¥ts
helm repo update

# 4. Installer ArgoCD avec les options de ligne de commande
helm install argocd argo/argo-cd --namespace argocd --kubeconfig /etc/rancher/k3s/k3s.yaml \
  --set server.service.type=NodePort

# V√©rification de l'installation d'ArgoCD
kubectl get pod -n argocd
```
<img width="1283" height="364" alt="image" src="https://github.com/user-attachments/assets/e424f1ad-1490-4129-9b93-6afc44ff8eeb" />
<img width="862" height="175" alt="image" src="https://github.com/user-attachments/assets/43643681-52a9-48e8-a50d-0bad80733f26" />

### Acc√®s √† l'interface ArgoCD

V√©rifiez que le service cr√©√© par votre stack Argo est bien expos√© sur le port 30080.
Ouvrez votre navigateur et allez sur `[https://VOTRE_IP_PUBLIC:30080](https://54.234.45.177:30080)`. Ignorez l'avertissement de s√©curit√© (le certificat est auto-sign√©).

<img width="1906" height="759" alt="image" src="https://github.com/user-attachments/assets/49b22cb7-954b-4707-9616-9620ad569da6" />


Le nom d'utilisateur est `admin`. Pour obtenir le mot de passe initial :

```bash
# Ce mot de passe est stock√© dans un secret Kubernetes
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
```

<img width="1226" height="48" alt="image" src="https://github.com/user-attachments/assets/589a462b-5d3b-4c80-be01-1d70f4deea01" />

Connectez-vous. Vous √™tes sur le tableau de bord d'ArgoCD !

<img width="1911" height="778" alt="image" src="https://github.com/user-attachments/assets/33bb4545-1e3e-4163-b3c7-8a9bf0d6fbf3" />


## 4. Atelier 2 : D√©ploiement d'Applications 

ArgoCD est extr√™mement flexible. Il peut d√©ployer des applications √† partir de diff√©rentes sources de manifestes. Dans cet atelier, nous allons explorer les sc√©narios courants qui illustrent cette flexibilit√© √† savoir helm et les manifest yaml.

### Cas 1 : D√©ploiement d'Odoo 18 avec GitOps

**Le Contexte : Un Sc√©nario d'Entreprise**

Imaginons que nous travaillons pour une entreprise qui utilise **Odoo**, un Progiciel de Gestion Int√©gr√© (ERP) tr√®s complet. Odoo est une application critique : il g√®re la comptabilit√©, les ventes, les stocks, les ressources humaines, etc. La fiabilit√© et la stabilit√© de son d√©ploiement sont donc primordiales.

Notre mission, en tant qu'√©quipe DevOps, est d'automatiser le d√©ploiement d'Odoo sur Kubernetes de mani√®re robuste, auditable et reproductible.

**La Solution : GitOps avec ArgoCD**

Pour ce faire, nous adoptons une approche GitOps. Au lieu de nous connecter manuellement au cluster pour y appliquer des commandes, nous d√©crivons l'√©tat d√©sir√© de notre application dans un d√©p√¥t Git. ArgoCD se charge ensuite de faire de cette description une r√©alit√© dans le cluster.

Les avantages sont immenses :
- **Fiabilit√© :** Git devient la source unique de v√©rit√©. Fini les "√ßa marche sur ma machine" ou les configurations qui d√©rivent apr√®s des interventions manuelles.
- **Automatisation :** Toute modification de la charte Helm (mise √† jour d'Odoo, changement de configuration) pouss√©e sur Git est automatiquement d√©ploy√©e.
- **Audit et S√©curit√© :** L'historique de Git nous dit exactement qui a chang√© quoi et quand. Les d√©veloppeurs n'ont plus besoin d'acc√®s directs au cluster de production.
- **Rollbacks Simplifi√©s :** Un probl√®me en production ? Un simple `git revert` permet de revenir √† la version stable pr√©c√©dente.

Pour cet atelier, notre entreprise a d√©j√† "packag√©" Odoo dans sa propre charte Helm, qui se trouve ici : `https://github.com/nzapanarcisse/datascientest-chart.git`.

**D√©ployons Odoo avec ArgoCD**

1.  **Cliquez sur `+ NEW APP`** sur l'interface d'ArgoCD.
2.  **Remplissez les informations g√©n√©rales :**
    *   **Application Name** : `odoo` (Un nom simple pour identifier notre application).
    *   **Project Name** : `default` (Nous utilisons le projet par d√©faut d'ArgoCD).

3.  **Configurez la politique de synchronisation (Sync Policy) :**
    *   **Sync Policy** : `Automatic`
    *   Cette option est le c≈ìur de l'automatisation. Elle indique √† ArgoCD de ne pas se contenter de d√©tecter les diff√©rences entre Git et le cluster, mais de les corriger **automatiquement**.
    *   **Cochez `Prune Resources`** : Imaginez que vous supprimez une ressource (un Service, un ConfigMap) de votre charte Helm. Sans cette option, la ressource continuerait d'exister dans le cluster. `Prune` s'assure qu'ArgoCD supprime les ressources qui n'existent plus dans Git, √©vitant ainsi les "ressources orphelines".
    *   **Cochez `Self Heal`** : C'est la garantie anti-d√©rive. Si un administrateur (ou vous-m√™me par erreur) modifie une ressource en direct avec `kubectl` (par exemple, changer le nombre de r√©plicas), ArgoCD le d√©tectera comme une d√©viation par rapport √† la source de v√©rit√© (Git) et **annulera automatiquement** ce changement. Le cluster "s'auto-gu√©rira" pour revenir √† l'√©tat d√©crit dans Git.

<img width="1915" height="549" alt="image" src="https://github.com/user-attachments/assets/3f3f9a52-65b4-48ed-9183-60bf5ba91abc" />

4.  **D√©finissez la Source de l'application :**
    *   **Repository URL** : `https://github.com/nzapanarcisse/datascientest-chart.git` (L'URL de notre charte Helm d'entreprise).
    *   **Revision** : `HEAD` (Indique √† ArgoCD de toujours suivre la derni√®re version de la branche par d√©faut).
    *   **Path** : `odoo` (Le dossier √† l'int√©rieur du d√©p√¥t Git qui contient les fichiers de la charte Helm).

5.  **Choisissez la Destination du d√©ploiement :**
    *   **Cluster URL** : `https://kubernetes.default.svc` (L'alias pour le cluster sur lequel ArgoCD est lui-m√™me install√©).
    *   **Namespace** : `odoo` (Nous d√©ploierons Odoo dans son propre espace de noms pour l'isoler des autres applications).

<img width="1884" height="813" alt="image" src="https://github.com/user-attachments/assets/73cb0430-b037-4235-b4f4-650d76bb1c35" />

6.  **Param√®tres de la Charte Helm :**
    *   Dans la section **Helm**, cliquez sur `Parameters`. Nous devons indiquer √† notre charte de cr√©er le namespace pour nous (cette option est sp√©cifique √† la charte Bitnami que nous utilisons comme base).
    *   Ajoutez un param√®tre : **Name**: `namespace.create`, **Value**: `true`.

7.  **Cliquez sur `CREATE`** en haut de la page.

<img width="1905" height="889" alt="image" src="https://github.com/user-attachments/assets/12dc198f-34f8-4c87-a29c-4a7fcb078c3c" />


**Que se passe-t-il ensuite ?**

ArgoCD va d'abord cloner le d√©p√¥t Git, puis comparer l'√©tat de la charte Helm avec ce qui existe dans le namespace `odoo` du cluster. Il verra que rien n'existe et marquera l'application comme `OutOfSync`. Puisque nous avons choisi une politique `Automatic`, il va imm√©diatement commencer le d√©ploiement.

Observez l'application passer par les √©tats `Progressing` puis `Healthy` et `Synced`. Vous pouvez cliquer sur l'application pour explorer toutes les ressources Kubernetes (Deployments, Services, PersistentVolumeClaims, etc.) qui ont √©t√© cr√©√©es, le tout sans une seule ligne de `kubectl` !

<img width="1299" height="508" alt="image" src="https://github.com/user-attachments/assets/fb66e28f-ccff-473a-830c-4d0ed67ea85f" />


En cliquant sur votre application Odoo depuis le tableau de bord Argo, vous pouvez voir les ressources en cours de cr√©ation sur votre cluster.

<img width="1296" height="609" alt="image" src="https://github.com/user-attachments/assets/a054e4d9-2254-4fb0-9a29-e5c28db6feef" />

Vous pouvez aussi vous connecter √† votre cluster et v√©rifier la cr√©ation de ces ressources.

<img width="1285" height="230" alt="image" src="https://github.com/user-attachments/assets/de614c8c-c09f-4ea2-bb7c-c9fb5c31b0a2" />

F√©licitations pour votre succ√®s ! √Ä ce stade, chaque fois qu'une modification sera apport√©e au d√©p√¥t datascientest-chart, Argo CD d√©tectera ces changements et les appliquera sur le cluster. De plus, si un d√©veloppeur ou un administrateur tente de modifier une ressource directement sur le cluster, Argo CD annulera cette modification.

<img width="1914" height="487" alt="image" src="https://github.com/user-attachments/assets/9f1a4096-af81-4572-bbfd-8910c43a331f" />


<img width="1306" height="596" alt="image" src="https://github.com/user-attachments/assets/943c0e7e-a957-471b-bdd7-55de235ed6cb" />

Ouvrez votre navigateur et allez sur `[http://VOTRE_IP_PUBLIC:30089](https://54.234.45.177:30089)`(v√©rifiz que ce port est bien ouvert sur votre groupe de s√©curit√©)

<img width="1920" height="777" alt="image" src="https://github.com/user-attachments/assets/c558e8f7-c4d9-4126-a24c-ed3249d423da" />

R√©cup√©rez le mot de passe d'Odoo √† partir du secret Odoo cr√©√© par la stack en ex√©cutant la commande suivante :
```bash
kubectl -n odoo get secret odoo -o jsonpath="{.data.odoo-password}" | base64 -d
```
<img width="1892" height="37" alt="image" src="https://github.com/user-attachments/assets/3651a9a7-d13c-4ff2-9514-3da18fe02cfa" />

user:user@example.com
dz6UiV0NUR

<img width="1913" height="996" alt="image" src="https://github.com/user-attachments/assets/b2b4afbc-e8de-4410-8331-4ef882468126" />

### Cas 2 : D√©ploiement d'une Application Web (Chart Helm Interne)

**Le Contexte : Standardisation des D√©ploiements**

Continuons notre sc√©nario. L'entreprise, satisfaite du d√©ploiement d'Odoo, souhaite maintenant d√©ployer sa propre application web. L'√©quipe "Plateforme" (dont nous faisons partie) veut standardiser les d√©ploiements. Elle impose l'utilisation de **Helm** pour toutes les nouvelles applications, car cela permet de cr√©er des "mod√®les" de d√©ploiement r√©utilisables et de g√©rer la configuration de mani√®re centralis√©e.

Notre mission est de packager l'application web (dont le code source se trouve dans le dossier `app/` de ce projet) dans une charte Helm et de la d√©ployer avec ArgoCD.

**La Solution : Une Charte Helm pour notre App**

Nous avons d√©j√† cr√©√© une charte Helm pour cette application et l'avons plac√©e dans le m√™me d√©p√¥t Git que la charte Odoo, mais dans un autre dossier.

*   **Source de la charte :** `https://github.com/nzapanarcisse/datascientest-chart.git`
*   **Chemin dans le d√©p√¥t :** `webapp/webapp-chart`

**D√©ployons notre application web avec sa charte Helm :**

1.  **Cliquez sur `+ NEW APP`**.
2.  **Informations G√©n√©rales :**
    *   **Application Name** : `webapp`
    *   **Project Name** : `default`
3.  **Politique de Synchronisation :** `Automatic`, avec `Prune Resources` et `Self Heal`.
4.  **Source :**
    *   **Repository URL** : `https://github.com/nzapanarcisse/datascientest-chart.git` (le m√™me d√©p√¥t que pour Odoo).
    *   **Revision** : `HEAD`
    *   **Path** : `webapp/webapp-chart` (le chemin vers notre nouvelle charte).
5.  **Destination :**
    *   **Cluster URL** : `https://kubernetes.default.svc`
    *   **Namespace** : `webapp`
6.  **Cliquez sur `CREATE`**.

ArgoCD va maintenant d√©ployer notre application web en utilisant la charte Helm que nous avons d√©finie. Cela montre comment une entreprise peut g√©rer ses propres applications packag√©es de mani√®re standardis√©e.

<img width="1915" height="1007" alt="image" src="https://github.com/user-attachments/assets/2d4614a7-9a7b-40be-a736-09b50f3a8e9e" />

<img width="1910" height="903" alt="image" src="https://github.com/user-attachments/assets/1b548df3-f19a-4215-9b84-8be7c3f2f545" />

V√©rification cr√©ation de l'application sur le cluster :

<img width="1900" height="270" alt="image" src="https://github.com/user-attachments/assets/483f1d6a-d988-4a5f-bf1b-5618d158bfbf" />

Ouvrez le navigateur et allez sur `[http://VOTRE_IP_PUBLIC:30000](https://54.234.45.177:30000)`(v√©rifiz que ce port est bien ouvert sur votre groupe de s√©curit√©)

<img width="1908" height="954" alt="image" src="https://github.com/user-attachments/assets/49a8ec38-dada-49f8-81ad-c191aa51eef1" />


### Cas 3 : D√©ploiement d'une Application Web (Manifestes Kubernetes Bruts)

**Le Contexte : Flexibilit√© pour les √âquipes**

Un mois plus tard, une nouvelle √©quipe de d√©veloppement rejoint l'entreprise. Ils ne sont pas encore form√©s √† Helm et trouvent sa syntaxe complexe. Pour leur projet, ils pr√©f√®rent utiliser des **manifestes Kubernetes de base** (`deployment.yaml`, `service.yaml`), car c'est un format qu'ils ma√Ætrisent d√©j√†.

Notre r√¥le, en tant qu'√©quipe DevOps, est de leur montrer qu'ils peuvent tout de m√™me b√©n√©ficier des avantages du GitOps et d'ArgoCD, m√™me sans utiliser Helm.

**La Solution : Le GitOps avec des Manifestes Simples**

Nous avons pris les m√™mes composants (un d√©ploiement et un service) et les avons d√©finis dans des fichiers YAML standards. Nous les avons plac√©s dans le m√™me d√©p√¥t central, mais dans un chemin diff√©rent.

*   **Source des manifestes :** `https://github.com/nzapanarcisse/datascientest-chart.git`
*   **Chemin dans le d√©p√¥t :** `webapp/webapp-manifest`

**D√©ployons la m√™me application avec des manifestes bruts :**

1.  **Cliquez sur `+ NEW APP`**.
2.  **Informations G√©n√©rales :**
    *   **Application Name** : `webapp-manifest`
    *   **Project Name** : `default`
3.  **Politique de Synchronisation :** `Automatic`, avec `Prune Resources` et `Self Heal`.
4.  **Source :**
    *   **Repository URL** : `https://github.com/nzapanarcisse/datascientest-chart.git`
    *   **Revision** : `HEAD`
    *   **Path** : `webapp/webapp-manifest` (le chemin vers nos fichiers YAML).
5.  **Destination :**
    *   **Cluster URL** : `https://kubernetes.default.svc`
    *   **Namespace** : `webapp-manifest` (un namespace diff√©rent pour √©viter les conflits).
6.  **Cliquez sur `CREATE`**.

ArgoCD va lire les fichiers `deployment.yaml` et `service.yaml` et les appliquer au cluster. Le r√©sultat final est le m√™me (l'application est d√©ploy√©e), mais nous avons utilis√© une m√©thode diff√©rente. Cela prouve aux √©quipes qu'ArgoCD s'adapte √† leurs comp√©tences tout en garantissant une gestion centralis√©e et bas√©e sur Git.

<img width="1892" height="991" alt="image" src="https://github.com/user-attachments/assets/52b48e4f-2e6b-41f9-aaaa-860a6a3f231b" />


<img width="1891" height="1032" alt="image" src="https://github.com/user-attachments/assets/792b843e-9fa2-490e-b791-0a238750e1ef" />

V√©rification cr√©ation de l'application sur le cluster :

<img width="1918" height="260" alt="image" src="https://github.com/user-attachments/assets/f5b85862-0c14-4e46-a2d7-94205abe8baa" />


Ouvrez le navigateur et allez sur `[http://VOTRE_IP_PUBLIC:30001](https://54.234.45.177:30001)`(v√©rifiz que ce port est bien ouvert sur votre groupe de s√©curit√©)

<img width="1882" height="915" alt="image" src="https://github.com/user-attachments/assets/19a62dc2-1e08-4e0b-8d9f-14601191796d" />


## 5. Atelier 3 : Automatisation Compl√®te avec un Pipeline CI/CD GitOps

**Le Contexte : Passer √† la Vitesse Sup√©rieure**

F√©licitations ! Dans l'atelier pr√©c√©dent, nous avons d√©ploy√© notre application web de deux mani√®res diff√©rentes. C'√©tait une √©tape cruciale pour comprendre le fonctionnement d'ArgoCD. Cependant, le processus √©tait encore manuel. Un d√©veloppeur modifiait le code, puis un membre de l'√©quipe DevOps devait manuellement cr√©er une nouvelle image, la pousser, et mettre √† jour la configuration dans le d√©p√¥t GitOps.

Ce processus est lent, source d'erreurs et ne correspond pas √† la v√©locit√© attendue d'une √©quipe moderne. La direction souhaite maintenant une **automatisation de bout en bout**. L'objectif est simple : **lorsqu'un d√©veloppeur pousse une modification du code de l'application, celle-ci doit √™tre test√©e, s√©curis√©e et d√©ploy√©e en production en quelques minutes, sans aucune intervention manuelle.**

C'est ici que la magie du CI/CD coupl√© au GitOps op√®re. Nous allons construire un pipeline avec GitHub Actions qui orchestrera tout ce processus.

**La Strat√©gie : Deux D√©p√¥ts pour Deux Responsabilit√©s**

Pour un pipeline GitOps robuste, la meilleure pratique est de s√©parer les pr√©occupations en utilisant deux d√©p√¥ts Git distincts :

1.  **D√©p√¥t Applicatif (`argocd-datascientest`) :** C'est l√† que vit le code source de notre application web (le dossier `app/`). C'est le terrain de jeu des d√©veloppeurs. Un `git push` sur ce d√©p√¥t d√©clenchera notre pipeline d'Int√©gration Continue (CI).

2.  **D√©p√¥t de Configuration/GitOps (`datascientest-chart`) :** Il contient la "v√©rit√©" sur l'√©tat de notre infrastructure (nos charts Helm, nos manifestes). C'est le d√©p√¥t surveill√© par ArgoCD. Seul notre pipeline CI/CD a le droit d'√©crire dedans.

![CI/CD GitOps Flow](https://i.imgur.com/gC0m3fC.png)

Ce d√©couplage est fondamental : les d√©veloppeurs n'ont pas besoin de savoir comment leur code est d√©ploy√©, et l'√©quipe Ops garde le contr√¥le total sur la configuration des d√©ploiements.

### Mise en place du pipeline GitHub Actions

Nous allons maintenant construire le workflow qui r√©alise ce sc√©nario. Ce pipeline sera d√©clench√© par un push sur le dossier `app/` de notre d√©p√¥t applicatif.

**1. Cr√©ation du Fichier de Workflow**

Dans votre projet `argocd-datascientest`, cr√©ez le fichier `.github/workflows/cicd-pipeline.yml` pour le pipeline.

**2. Le Code du Workflow (`.github/workflows/cicd-pipeline.yml`)**

Copiez le code suivant dans votre fichier `.github/workflows/cicd-pipeline.yml`  ou fork√© le d√©pot pour avoir le projet sur votre propres repository.

```yaml
# =========================================================================================
# ==              PIPELINE DE CI/CD POUR L'APPLICATION WEB                             ==
# =========================================================================================
# == Ce workflow GitHub Actions est con√ßu pour automatiser le cycle de vie de          ==
# == notre application web, de la construction √† la synchronisation avec ArgoCD.       ==
# =========================================================================================

name: CI/CD - Pipeline de D√©ploiement de l'Application Web

# =========================================================================================
# ==                                     TRIGGERS                                        ==
# =========================================================================================
# == Le workflow se d√©clenche automatiquement dans les conditions suivantes :            ==
# ==  - Un `push` est effectu√© sur la branche `main`.                                   ==
# ==  - Les modifications concernent le r√©pertoire `app/`, o√π se trouve le code source. ==
# =========================================================================================
on:
  push:
    branches: [ "master" ]
    #paths:
    #  - 'app/**'

# =========================================================================================
# ==                                      JOBS                                         ==
# =========================================================================================
# == Le workflow est divis√© en plusieurs jobs qui s'ex√©cutent s√©quentiellement.        ==
# == Chaque job est une √©tape logique de notre pipeline : Build > Test > Scan > Push.    ==
# =========================================================================================
jobs:
  # =======================================================================================
  # == JOB 1: BUILD - Construction de l'image Docker                                    ==
  # =======================================================================================
  # == Objectif : Construire l'image Docker de l'application et la stocker en tant      ==
  # == qu'artefact pour les jobs suivants.                                               ==
  # =======================================================================================
  build:
    runs-on: ubuntu-latest
    outputs:
      image_tag: ${{ steps.generate_tag.outputs.tag }}
    steps:
      # --- √âtape 1.1 : R√©cup√©ration du code ---
      - name: 1.1. R√©cup√©ration du code source
        uses: actions/checkout@v4

      # --- √âtape 1.2 : G√©n√©ration d'un tag unique ---
      - name: 1.2. G√©n√©ration d'un tag unique pour l'image
        id: generate_tag
        run: echo "tag=$(echo $GITHUB_SHA | head -c7)" >> $GITHUB_OUTPUT

      # --- √âtape 1.3 : Configuration de Docker Buildx ---
      - name: 1.3. Configuration de Docker Buildx
        uses: docker/setup-buildx-action@v3

      # --- √âtape 1.4 : Build de l'image Docker ---
      - name: 1.4. Build de l'image Docker
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./app/Dockerfile
          push: false
          tags: datascientestuser/webapp:${{ steps.generate_tag.outputs.tag }}
          load: true

      # --- √âtape 1.5 : Sauvegarde de l'image en tant qu'artefact ---
      - name: 1.5. Sauvegarde de l'image Docker pour les jobs suivants
        run: docker save datascientestuser/webapp:${{ steps.generate_tag.outputs.tag }} -o image.tar
      - uses: actions/upload-artifact@v4
        with:
          name: docker-image
          path: image.tar

  # =======================================================================================
  # == JOB 2: TEST - Test de fum√©e (Smoke Test) de l'application                       ==
  # =======================================================================================
  # == Objectif : D√©marrer le conteneur et v√©rifier qu'il r√©pond correctement.         ==
  # =======================================================================================
  test-acceptance:
    runs-on: ubuntu-latest
    needs: build
    steps:
      # --- √âtape 2.1 : R√©cup√©ration de l'artefact de l'image ---
      - name: 2.1. R√©cup√©ration de l'image Docker
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      # --- √âtape 2.2 : Chargement de l'image ---
      - name: 2.2. Chargement de l'image Docker
        run: docker load -i image.tar

      # --- √âtape 2.3 : Lancement du conteneur ---
      - name: 2.3. Lancement du conteneur pour le test
        run: |
          docker run -d -p 8080:80 --name webapp-test datascientestuser/webapp:${{ needs.build.outputs.image_tag }}
          echo "IMAGE_TAG=${{ needs.build.outputs.image_tag }}" >> $GITHUB_ENV

      # --- √âtape 2.4 : Test de l'application ---
      - name: 2.4. Test de la r√©ponse de l'application
        run: |
          echo "Attente du d√©marrage de l'application..."
          sleep 10
          echo "V√©rification du contenu de la page d'accueil..."
          curl -s http://localhost:8080 | grep "Dimension"

      # --- √âtape 2.5 : Nettoyage ---
      - name: 2.5. Arr√™t et suppression du conteneur de test
        if: always() # S'ex√©cute toujours, m√™me si l'√©tape de test a √©chou√©
        run: |
          docker stop webapp-test
          docker rm webapp-test

  # =======================================================================================
  # == JOB 3: SCAN - Analyse de vuln√©rabilit√©s de l'image                               ==
  # =======================================================================================
  # == Objectif : Scanner l'image pour d√©tecter des vuln√©rabilit√©s de s√©curit√©.         ==
  # =======================================================================================
  test-qualite:
    runs-on: ubuntu-latest
    needs: [build, test-acceptance]
    steps:
      - name: 3.1. R√©cup√©ration de l'image Docker
        uses: actions/download-artifact@v4
        with:
          name: docker-image
      - name: 3.2. Chargement de l'image Docker
        run: |
          docker load -i image.tar
          echo "IMAGE_TAG=${{ needs.build.outputs.image_tag }}" >> $GITHUB_ENV

      - name: 3.3. Scan de vuln√©rabilit√©s avec Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'datascientestuser/webapp:${{ env.IMAGE_TAG }}'
          format: 'table'
          exit-code: '1'
          ignore-unfixed: true
          vuln-type: 'os,library'
          severity: 'CRITICAL,HIGH'

  # =======================================================================================
  # == JOB 4: PUSH - Publication de l'image Docker                                      ==
  # =======================================================================================
  # == Objectif : Pousser l'image, si elle est s√ªre, vers le registre Docker Hub.       ==
  # =======================================================================================
  push:
    runs-on: ubuntu-latest
    needs: [build, test-qualite]
    steps:
      - name: 4.1. R√©cup√©ration de l'image Docker
        uses: actions/download-artifact@v4
        with:
          name: docker-image
      - name: 4.2. Chargement de l'image Docker
        run: |
          docker load -i image.tar
          echo "IMAGE_TAG=${{ needs.build.outputs.image_tag }}" >> $GITHUB_ENV

      - name: 4.3. Connexion √† Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: 4.4. Push de l'image sur Docker Hub
        run: docker push datascientestuser/webapp:${{ env.IMAGE_TAG }}

  # =======================================================================================
  # == JOB 5: DEPLOY - D√©clenchement de la synchronisation ArgoCD                        ==
  # =======================================================================================
  # == Objectif : Mettre √† jour le d√©p√¥t GitOps pour qu'ArgoCD d√©ploie la nouvelle image. ==
  # =======================================================================================
  trigger-argocd-sync:
    runs-on: ubuntu-latest
    needs: [build, push]
    steps:
      - name: 5.1. Checkout du d√©p√¥t de Configuration (GitOps)
        uses: actions/checkout@v4
        with:
          repository: nzapanarcisse/datascientest-chart
          token: ${{ secrets.GITOPS_PAT }}

      - name: 5.2. Mise √† jour du tag de l'image dans le chart Helm
        run: |
          sed -i "s/^  tag: .*/  tag: ${{needs.build.outputs.image_tag}}/" webapp/webapp-chart/values.yaml

      - name: 5.3. Commit et Push des changements vers le d√©p√¥t GitOps
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          git add webapp/webapp-chart/values.yaml
          git diff --staged --quiet || git commit -m "CI: Mise √† jour de l'image webapp vers le tag ${{needs.build.outputs.image_tag}}"
          git push
```

**3. Configuration des Secrets**

Ce pipeline a besoin de trois secrets pour fonctionner. Allez dans votre d√©p√¥t `argocd-datascientest`, puis dans `Settings > Secrets and variables > Actions` et ajoutez les secrets suivants :

*   `DOCKER_USERNAME`: `datascientestuser` ou username votre compte docker
*   `DOCKER_PASSWORD`: `datascientestuser` ou password de votre compte docker
*   `GITOPS_PAT`: Il s'agit d'un **Personal Access Token (PAT)** de GitHub. C'est crucial.
    *   Allez dans les [param√®tres de votre compte GitHub](https://github.com/settings/tokens) (profile > setting > devoloper setting > `Personal access tokens` > `Tokens (classic)`.)
    *   G√©n√©rez un nouveau token.
    *   Donnez-lui un nom (ex: `argocd-trigger`).
    *   **Cochez la case `repo`** pour lui donner les droits de lire et √©crire dans vos d√©p√¥ts.
    *   Copiez ce token et collez-le comme valeur pour le secret `GITOPS_PAT`.

<img width="1899" height="692" alt="image" src="https://github.com/user-attachments/assets/295f34d1-49c5-47a5-b9eb-db85b513d93f" />

<img width="1920" height="979" alt="image" src="https://github.com/user-attachments/assets/82943b16-f376-439f-84ea-56e292272cf9" />

### D√©monstration du Workflow Automatis√©

Maintenant, il est temps de voir la magie op√©rer. Le test ultime !

1.  **Assurez-vous que votre application `webapp` dans ArgoCD est bien configur√©e** pour pointer vers le chemin `webapp/webapp-chart` du d√©p√¥t `datascientest-chart` et que la synchronisation automatique est activ√©e.

2.  **Faites une modification visible dans le code de l'application.**
    Ouvrez le fichier `app/static-website-example/index.html` et changez le titre `<h1>`.
    Par exemple : `<h1>Mon App est maintenant automatis√©e !</h1>`

3.  **Poussez le changement sur GitHub.**
    ```bash
    git add app/static-website-example/index.html
    git commit -m "feat: Mise √† jour du titre de la page d'accueil"
    git push origin main
    ```

4.  **Observez le spectacle !**
    *   **√âtape 1 (GitHub Actions) :** Allez dans l'onglet "Actions" de votre d√©p√¥t `argocd-datascientest`. Vous verrez votre pipeline se d√©clencher. Suivez les √©tapes : build, test-acceptance,test-qualit√©, push, et surtout le dernier job `trigger-argocd-sync` qui va commiter dans l'autre d√©p√¥t.

      <img width="1928" height="701" alt="image" src="https://github.com/user-attachments/assets/850f546d-25dc-4508-b737-da3eeb135abf" />

    *   **√âtape 2 (D√©p√¥t GitOps) :** Une fois le pipeline termin√©, allez sur votre d√©p√¥t `datascientest-chart`. Vous verrez un nouveau commit fait par "GitHub Actions Bot" qui a modifi√© le tag de l'image dans `webapp/webapp-chart/values.yaml`.
      
      <img width="1877" height="578" alt="image" src="https://github.com/user-attachments/assets/817e163d-b6fc-47ca-851a-10d3f4c9ac29" />

    *   **√âtape 3 (ArgoCD) :** Allez sur votre interface ArgoCD. Cliquez sur le bouton `Refresh` de l'application `webapp-helm`. ArgoCD va d√©tecter que l'√©tat d√©sir√© dans Git a chang√© (le tag de l'image n'est plus le m√™me). L'application va passer √† l'√©tat `OutOfSync`.
    *   **√âtape 4 (D√©ploiement) :** Puisque la politique de synchronisation est `Automatic`, ArgoCD va imm√©diatement commencer le d√©ploiement. Il va cr√©er un nouveau ReplicaSet, d√©marrer de nouveaux pods avec la nouvelle image, et une fois qu'ils sont pr√™ts, il va supprimer les anciens. C'est un d√©ploiement `RollingUpdate` sans interruption de service.

5.  **V√©rifiez le r√©sultat.**
    Une fois l'application `Synced` et `Healthy` dans ArgoCD, rafra√Æchissez la page de votre application web dans votre navigateur. Vous devriez voir le nouveau titre que vous avez modifi√© !

   <img width="1875" height="967" alt="image" src="https://github.com/user-attachments/assets/86dd3e47-fa7d-4577-a1ec-8707d1d42aa7" />

Vous venez de mettre en place un workflow CI/CD GitOps complet, s√©curis√© et enti√®rement automatis√©. C'est le standard de l'industrie et une comp√©tence extr√™mement recherch√©e.

## 6. Concepts Avanc√©s

### ArgoCD et le Multi-Cluster

**Le Contexte : L'Expansion de l'Entreprise**

Notre entreprise conna√Æt une croissance rapide. Le d√©ploiement de toutes les applications (d√©veloppement, staging, production) sur un unique cluster Kubernetes n'est plus tenable. C'est un risque pour la stabilit√© : une mauvaise manipulation dans un environnement de test pourrait impacter la production. De plus, les √©quipes de d√©veloppement ont besoin d'un environnement de `staging` stable et isol√© pour valider leurs fonctionnalit√©s avant le lancement final.

**Notre Mission :** Mettre en place une architecture multi-environnements (`production` et `staging`) g√©r√©e de mani√®re centralis√©e, tout en respectant notre m√©thodologie GitOps.

**La Solution : Le Contr√¥le Multi-Cluster d'ArgoCD**

ArgoCD a √©t√© con√ßu pour cela. Une seule instance d'ArgoCD, tournant sur notre cluster principal (que nous appellerons d√©sormais le cluster `prod`), peut g√©rer des d√©ploiements sur un nombre illimit√© de clusters Kubernetes distants.

Nous allons enregistrer notre nouveau cluster `staging` aupr√®s de notre instance ArgoCD centrale. Cela nous permettra de :
-   **Garder un point de contr√¥le unique :** Toute la gestion des d√©ploiements se fait depuis une seule interface.
-   **Appliquer le GitOps partout :** La source de v√©rit√© reste Git, que l'on d√©ploie en `staging` ou en `prod`.
-   **Isoler les environnements :** Les clusters sont ind√©pendants, renfor√ßant la s√©curit√© et la stabilit√©.

#### √âtape 1 : Enregistrer un Cluster Externe

Supposons que vous ayez d√©j√† configur√© l'acc√®s √† votre nouveau cluster `staging` et que son contexte (`staging-context`) soit pr√©sent dans votre fichier `~/.kube/config` local.

1.  **Installez la CLI d'ArgoCD** sur votre machine locale si ce n'est pas d√©j√† fait.

2.  **Connectez-vous √† votre instance ArgoCD :**
    ```bash
    # Remplacez l'IP par celle de votre serveur ArgoCD
    argocd login <ARGO_CD_SERVER_IP>
    ```

3.  **Listez les contextes Kubernetes connus par votre machine locale :**
    ```bash
    kubectl config get-contexts
    # Vous devriez voir le contexte de votre cluster de production et celui de staging.
    ```

4.  **Enregistrez le nouveau cluster `staging` aupr√®s d'ArgoCD :**
    ```bash
    # Remplacez <STAGING_CONTEXT_NAME> par le nom du contexte de votre cluster de staging
    argocd cluster add <STAGING_CONTEXT_NAME>
    ```
    Cette commande est puissante. ArgoCD va se connecter au cluster distant, y cr√©er un `ServiceAccount`, un `ClusterRole` et un `ClusterRoleBinding`. Cela lui donne les permissions n√©cessaires pour g√©rer les ressources sur ce cluster distant, sans jamais exposer les credentials du cluster `staging` √† l'ext√©rieur.

#### √âtape 2 : D√©ployer une Application sur le Cluster de Staging

Maintenant que le cluster est enregistr√©, d√©ployer dessus est un jeu d'enfant. Nous allons d√©ployer notre application `webapp` sur ce nouvel environnement.

La meilleure pratique GitOps est de d√©finir l'application de mani√®re d√©clarative. Cr√©ons un fichier `webapp-staging-app.yaml` :

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  # Un nom qui identifie clairement l'application et son environnement
  name: webapp-staging
  namespace: argocd
spec:
  project: default
  source:
    # Le m√™me d√©p√¥t Git que pour la production
    repoURL: 'https://github.com/nzapanarcisse/datascientest-chart.git'
    path: webapp/webapp-chart
    targetRevision: HEAD # On peut aussi pointer vers une branche "staging"
  destination:
    # On cible le cluster distant !
    # Le nom est celui retourn√© par la commande `argocd cluster list`
    name: <NOM_DU_CLUSTER_STAGING>
    # On d√©ploie dans un namespace d√©di√© sur le cluster de staging
    namespace: webapp-staging
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    # Important : On demande √† ArgoCD de cr√©er le namespace s'il n'existe pas
    syncOptions:
    - CreateNamespace=true
```

Appliquez ce manifeste sur votre cluster principal (celui o√π tourne ArgoCD) :
```bash
kubectl apply -f webapp-staging-app.yaml -n argocd
```

Et voil√† ! Rendez-vous sur l'interface d'ArgoCD. Vous verrez une nouvelle application `webapp-staging`. En cliquant dessus, vous constaterez qu'elle d√©ploie ses ressources sur le cluster distant, prouvant que vous ma√Ætrisez d√©sormais une architecture multi-environnements enti√®rement pilot√©e par Git.

### Notifications avec Slack

**Le Contexte : Am√©liorer la Visibilit√© et la R√©activit√©**

Notre pipeline CI/CD est automatis√©, et ArgoCD garantit que nos clusters refl√®tent l'√©tat de Git. C'est excellent, mais l'√©quipe fonctionne encore en mode r√©actif. Pour savoir si un d√©ploiement a r√©ussi ou √©chou√©, un d√©veloppeur doit aller sur l'interface d'ArgoCD. Si quelque chose tourne mal, le temps de d√©tection d√©pend de la vigilance manuelle de l'√©quipe.

**Notre Mission :** Mettre en place un syst√®me de notifications proactives. L'√©quipe doit √™tre inform√©e en temps r√©el des √©v√©nements importants du cycle de vie de nos applications (d√©ploiement r√©ussi, √©chec, d√©gradation de la sant√©) directement dans son outil de communication principal : **Slack**.

**La Solution : L'Int√©gration `ArgoCD Notifications`**

ArgoCD dispose d'un sous-syst√®me puissant d√©di√© aux notifications. Il peut s'int√©grer √† des dizaines d'outils (Slack, Microsoft Teams, email, etc.). Nous allons le configurer pour qu'il envoie des messages clairs et contextuels √† un canal Slack d√©di√©.

Cela va cr√©er une boucle de feedback instantan√©e, permettant √† l'√©quipe de :
-   **C√©l√©brer les d√©ploiements r√©ussis.**
-   **R√©agir imm√©diatement en cas d'√©chec.**
-   **Maintenir un journal d'audit visible par tous.**

#### √âtape 1 : Cr√©er un Webhook sur Slack

1.  Allez sur `api.slack.com/apps`.
2.  Cr√©ez une nouvelle application pour votre workspace.
3.  Dans le menu `Features`, activez **Incoming Webhooks**.
4.  Cliquez sur **Add New Webhook to Workspace**, choisissez un canal (ex: `#deployments`) et autorisez.
5.  Copiez l'URL du webhook. Elle ressemble √† `https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX`.

#### √âtape 2 : Configurer ArgoCD Notifications

Nous devons stocker cette URL de webhook de mani√®re s√©curis√©e dans un Secret Kubernetes et informer le contr√¥leur de notifications comment l'utiliser.

1.  **Cr√©ez le Secret contenant l'URL du webhook :**
    ```bash
    kubectl apply -f - <<EOF
    apiVersion: v1
    kind: Secret
    metadata:
      name: argocd-notifications-secret
      namespace: argocd
    stringData:
      # La cl√© 'slack-url' est arbitraire, mais nous la r√©utiliserons
      slack-url: <VOTRE_URL_DE_WEBHOOK_SLACK>
    EOF
    ```

2.  **Modifiez le ConfigMap `argocd-notifications-cm` pour d√©finir le service Slack :**
    Ce ConfigMap est le cerveau des notifications. Nous y d√©finissons les "services" (comment se connecter √† Slack) et les "templates" (√† quoi ressembleront les messages).
    ```bash
    kubectl patch configmap argocd-notifications-cm -n argocd --type merge -p '{"data": {"service.slack": "url: $slack-url", "context": "slack-url: $slack-url"}}'
    ```
    *Note : Nous ajoutons `slack-url` au `context` pour le rendre disponible dans les templates de message.*

#### √âtape 3 : Cr√©er un Template de Message (Optionnel mais recommand√©)

Pour des messages plus riches, d√©finissons un template.
```bash
kubectl patch configmap argocd-notifications-cm -n argocd --type merge -p '{"data": {"template.on-sync-succeeded": "message: |\n  L''application {{.app.metadata.name}} a √©t√© synchronis√©e avec succ√®s.\n  Commit: `{{.app.status.sync.revision}}`\n  Auteur: {{.app.revisionMetadata.author}}\n  Consultez l''application ici: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}"}}'
```

#### √âtape 4 : S'abonner aux Notifications

Maintenant, il suffit de "dire" √† notre application qu'elle doit envoyer des notifications. Cela se fait via une simple annotation sur l'objet `Application` d'ArgoCD.

Modifions notre application `webapp` pour qu'elle notifie sur le canal `#deployments` √† chaque synchronisation r√©ussie.

```bash
# Remplacez 'webapp' par le nom de votre application et '#deployments' par votre canal
kubectl patch app webapp -n argocd -p '{"metadata": {"annotations": {"notifications.argoproj.io/subscribe.on-sync-succeeded.slack": "#deployments"}}}' --type merge
```
Cette annotation est tr√®s lisible : `subscribe` √† l'√©v√©nement `on-sync-succeeded` en utilisant le service `slack` et en envoyant au canal `#deployments`.

D√©sormais, chaque fois que l'application `webapp` sera synchronis√©e avec succ√®s (apr√®s un `git push` ou une action manuelle), un message appara√Ætra sur Slack, informant toute l'√©quipe en temps r√©el !

## 7. Conclusion

F√©licitations ! Vous avez non seulement appris √† utiliser un outil, mais vous avez adopt√© une **m√©thodologie compl√®te** qui transforme la mani√®re de livrer des logiciels. En parcourant ce cours, vous avez :

-   **Int√©rioris√© les principes fondamentaux du GitOps**, en faisant de Git la source unique de v√©rit√© pour l'√©tat de votre infrastructure.
-   **Construit un environnement de production r√©aliste** avec Kubernetes et ArgoCD, de l'installation √† la configuration.
-   **D√©ploy√© diverses applications** en utilisant les strat√©gies les plus courantes (Charts Helm, manifestes bruts), prouvant la flexibilit√© d'ArgoCD.
-   **Orchestr√© un pipeline CI/CD enti√®rement automatis√©** avec GitHub Actions, r√©alisant la promesse d'un d√©ploiement fluide et s√©curis√© du code √† la production.
-   **Explor√© des concepts avanc√©s et cruciaux** comme la gestion multi-cluster et les notifications, vous pr√©parant √† des sc√©narios d'entreprise complexes.

Le voyage ne s'arr√™te pas l√†. ArgoCD fait partie d'un √©cosyst√®me plus large. Nous vous encourageons √† explorer :
-   **Argo Rollouts :** Pour des strat√©gies de d√©ploiement avanc√©es (Canary, Blue-Green).
-   **Argo Workflows :** Pour orchestrer des t√¢ches parall√®les complexes en tant que workflows Kubernetes-natifs.
-   **Argo Events :** Pour d√©clencher des actions Kubernetes en r√©ponse √† des √©v√©nements externes (webhooks, messages, etc.).

Vous d√©tenez d√©sormais les cl√©s pour construire des plateformes de livraison continue robustes, s√©curis√©es et v√©loces. Le GitOps est plus qu'une comp√©tence technique, c'est un changement de culture, et vous √™tes maintenant pr√™t √† en √™tre l'ambassadeur. Bon d√©ploiement !

## 8. Examen de Validation : D√©ployez votre Propre Application

Cet examen a pour but de valider votre capacit√© √† appliquer les principes GitOps avec ArgoCD de mani√®re autonome. Vous devrez d√©ployer une nouvelle application, diagnostiquer un probl√®me et le corriger en suivant la m√©thodologie du cours.

### Objectif

D√©ployer une application web "Citation du Jour" bas√©e sur Python/Flask. L'application est intentionnellement mal configur√©e. Vous devrez utiliser les outils d'ArgoCD pour trouver le probl√®me, le corriger dans Git, et laisser ArgoCD synchroniser la solution.

### Contexte

L'application est un simple serveur web qui affiche une citation al√©atoire √† chaque fois que sa page d'accueil est rafra√Æchie.

**Code source de l'application (`app.py`) :**
```python
from flask import Flask
import random

app = Flask(__name__)

quotes = [
    "The only way to do great work is to love what you do. - Steve Jobs",
    "Innovation distinguishes between a leader and a follower. - Steve Jobs",
    "Your time is limited, don't waste it living someone else's life. - Steve Jobs",
    "Stay hungry, stay foolish. - Steve Jobs",
    "Talk is cheap. Show me the code. - Linus Torvalds"
]

@app.route('/')
def get_quote():
    return f"<h1>Quote of the Day</h1><p>{random.choice(quotes)}</p>"

if __name__ == '__main__':
    # L'application tourne sur le port 5000
    app.run(host='0.0.0.0', port=5000)
```

### √âtapes √† R√©aliser

1.  **Cr√©er la Structure du Projet :**
    *   Cr√©ez un nouveau dossier pour votre projet d'examen.
    *   √Ä l'int√©rieur, cr√©ez un fichier `app.py` avec le code ci-dessus.
    *   Cr√©ez un fichier `requirements.txt` contenant une seule ligne : `Flask`.

2.  **√âcrire le `Dockerfile` :**
    *   Cr√©ez un `Dockerfile` pour conteneuriser cette application Python.
    *   *Indice :* Utilisez une image de base Python (ex: `python:3.9-slim`), copiez les fichiers, installez les d√©pendances via `pip install -r requirements.txt`, et d√©finissez la commande de d√©marrage.

3.  **√âcrire les Manifestes Kubernetes :**
    *   Cr√©ez un dossier `k8s/`.
    *   √Ä l'int√©rieur, cr√©ez un `service.yaml` (de type `NodePort` pour simplifier).
    *   Cr√©ez un `deployment.yaml`. **Utilisez le manifeste ci-dessous qui contient une erreur volontaire.**

    **`k8s/deployment.yaml` (avec erreur) :**
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: quote-app-deployment
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: quote-app
      template:
        metadata:
          labels:
            app: quote-app
        spec:
          containers:
          - name: quote-app
            # Assurez-vous de remplacer par votre image
            image: VOTRE_USER/quote-app:latest
            ports:
            # Attention, il y a une erreur dans cette section
            - containerPort: 8080
    ```

4.  **Mettre en place le D√©p√¥t Git :**
    *   Cr√©ez un nouveau d√©p√¥t **priv√©** sur GitHub pour cet examen.
    *   Poussez tous vos fichiers (`app.py`, `requirements.txt`, `Dockerfile`, `k8s/`) sur ce d√©p√¥t.

5.  **Construire et Pousser l'Image Docker :**
    *   Construisez l'image Docker de votre application.
    *   Poussez-la sur un registre public (Docker Hub, GHCR...).
    *   Assurez-vous que le nom de l'image dans `deployment.yaml` correspond √† celle que vous avez pouss√©e. Poussez ce changement si n√©cessaire.

6.  **D√©ployer avec ArgoCD :**
    *   Connectez votre nouveau d√©p√¥t √† ArgoCD (si ce n'est pas d√©j√† fait via un PAT).
    *   Cr√©ez une nouvelle `Application` dans ArgoCD pointant vers le dossier `k8s` de votre d√©p√¥t d'examen.
    *   Utilisez une politique de synchronisation `Automatic` avec `Self Heal` et `Prune Resources`.

7.  **Diagnostiquer et Corriger :**
    *   Une fois l'application synchronis√©e, vous remarquerez qu'elle est `Progressing` mais pas `Healthy`. Les pods vont probablement entrer en `CrashLoopBackOff`.
    *   **Votre mission :** Utilisez l'interface d'ArgoCD pour inspecter l'√©tat de l'application.
        *   Cliquez sur le pod pour voir ses logs et ses √©v√©nements. Les logs devraient indiquer que le serveur d√©marre bien sur le port 5000. Les √©v√©nements du pod ou du ReplicaSet peuvent indiquer un √©chec des sondes de sant√© (health checks).
        *   Identifiez l'incoh√©rence entre le port expos√© par le conteneur (`5000`) et le port d√©clar√© dans le `deployment.yaml` (`8080`).
    *   **Correction :**
        *   Modifiez le fichier `k8s/deployment.yaml` **dans votre d√©p√¥t Git** pour corriger le `containerPort`.
        *   Poussez le commit de correction.
        *   Observez ArgoCD d√©tecter le changement, se re-synchroniser et voir l'application devenir enfin `Healthy`.

### Crit√®res de R√©ussite

Vous avez r√©ussi l'examen si :
*   ‚úÖ L'application `quote-app` est visible dans ArgoCD.
*   ‚úÖ L'application est `Synced` et `Healthy`.
*   ‚úÖ Le commit de correction de `deployment.yaml` est visible dans l'historique Git de votre d√©p√¥t.
*   ‚úÖ Vous pouvez acc√©der √† l'application via son `NodePort` et voir une citation s'afficher dans votre navigateur.

<details>
  <summary>Cliquez ici pour voir la solution</summary>
  
  ---
  
  **Le Probl√®me :**
  
  Le code de l'application Flask (`app.py`) d√©marre un serveur sur le port `5000`. Cependant, le manifeste `deployment.yaml` d√©clare que le conteneur expose le port `8080`. Kubernetes ne peut donc pas router correctement le trafic ou v√©rifier la sant√© du pod sur le bon port, ce qui cause le crash.
  
  **La Solution :**
  
  Il fallait corriger le `containerPort` dans le fichier `k8s/deployment.yaml` pour qu'il corresponde au port de l'application.
  
  **`k8s/deployment.yaml` (corrig√©) :**
  ```yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: quote-app-deployment
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: quote-app
    template:
      metadata:
        labels:
          app: quote-app
      spec:
        containers:
        - name: quote-app
          image: VOTRE_USER/quote-app:latest # Votre image
          ports:
          # Le port est maintenant correct
          - containerPort: 5000 
  ```
  En poussant ce changement sur Git, ArgoCD d√©tecte la mise √† jour, applique le nouveau manifeste, et le pod d√©marre correctement, rendant l'application `Healthy`.
  
</details>
